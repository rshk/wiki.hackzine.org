<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Grabbing a whole site using wget &mdash; Hackzine Wiki</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Hackzine Wiki" href="../index.html" />
    <link rel="up" title="Scripts" href="index.html" />
    <link rel="next" title="Contributing" href="../contributing.html" />
    <link rel="prev" title="Scripts" href="index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../contributing.html" title="Contributing"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Scripts"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">Hackzine Wiki</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">Scripts</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            

  <div class="section" id="grabbing-a-whole-site-using-wget">
<h1>Grabbing a whole site using wget<a class="headerlink" href="#grabbing-a-whole-site-using-wget" title="Permalink to this headline">¶</a></h1>
<p>Recently, I needed an off-line copy of some documentation, available only as
web pages. That&#8217;s how I managed to clone entire parts of websites using wget.</p>
<p>First of all, the whole command I use:</p>
<div class="highlight-python"><div class="highlight"><pre>wget -U &quot;Mozilla/5.0 (X11; U; Linux; en-US; rv:1.9.1.16) Gecko/20110929 Firefox/3.5.16&quot; \
    --recursive --level=1 --no-clobber --page-requisites --html-extension \
    --convert-links --no-parent \
    --wait=3 --random-wait \
    http://www.example.com/docs/interesting-part/ --domains=www.example.com
</pre></div>
</div>
<div class="section" id="basic-arguments">
<h2>Basic arguments<a class="headerlink" href="#basic-arguments" title="Permalink to this headline">¶</a></h2>
<p>These are the basic arguments needed to perform the recursive download.</p>
<dl class="docutils">
<dt><tt class="docutils literal"><span class="pre">--recursive</span></tt></dt>
<dd>Tells wget to recursively download pages, starting from the specified URL.</dd>
<dt><tt class="docutils literal"><span class="pre">--level=1</span></tt></dt>
<dd>Tells wget to stop after one level of recursion. This can be changed to download more deeply, or set to 0 that means &#8220;no limit&#8221;</dd>
<dt><tt class="docutils literal"><span class="pre">--no-clobber</span></tt></dt>
<dd>Skip downloads that would download to existing files</dd>
<dt><tt class="docutils literal"><span class="pre">--page-requisites</span></tt></dt>
<dd>Tells wget to download all the resources (images, css, javascript, ...) that are needed for the page to work.</dd>
<dt><tt class="docutils literal"><span class="pre">--html-extension</span></tt></dt>
<dd>Adds &#8221;.html&#8221; extension to downloaded files, with the double purpose of making the browser recognize them as html files and solving naming conflicts for &#8220;generated&#8221; URLs, when there are no directories with &#8220;index.html&#8221; but just a framework that responds dynamically with generated pages.</dd>
<dt><tt class="docutils literal"><span class="pre">--convert-links</span></tt></dt>
<dd>After the download is complete, convert the links in the document to make them suitable for local viewing. This affects not only the visible hyperlinks, but any part of the document that links to external content, such as embedded images, links to style sheets, hyperlinks to non-HTML content, etc.</dd>
<dt><tt class="docutils literal"><span class="pre">--no-parent</span></tt></dt>
<dd>Do not ever ascend to the parent directory when retrieving recursively.</dd>
<dt><tt class="docutils literal"><span class="pre">--domains=www.example.com</span></tt></dt>
<dd>Set domains to be followed. DOMAIN-LIST is a comma-separated list of domains.</dd>
</dl>
</div>
<div class="section" id="avoiding-imposed-download-limits">
<h2>Avoiding imposed download limits<a class="headerlink" href="#avoiding-imposed-download-limits" title="Permalink to this headline">¶</a></h2>
<p>Many web servers tend to limit the pages a user can download in a given amount
of time, or the user-agents that can access given pages, etc.
To avoid such limits, some extra options may be added.</p>
<dl class="docutils">
<dt><tt class="docutils literal"><span class="pre">-U</span> <span class="pre">&quot;Mozilla/5.0</span> <span class="pre">(X11;</span> <span class="pre">U;</span> <span class="pre">Linux;</span> <span class="pre">en-US;</span> <span class="pre">rv:1.9.1.16)</span> <span class="pre">Gecko/20110929</span> <span class="pre">Firefox/3.5.16&quot;</span></tt></dt>
<dd>Tells wget to use a fake user-agent, to emulate the one of a web browser (in this case, Firefox 3.5 on Linux)</dd>
<dt><tt class="docutils literal"><span class="pre">--wait=3</span></tt></dt>
<dd>Tells wget to wait at least 3 seconds between retrievals.</dd>
<dt><tt class="docutils literal"><span class="pre">--random-wait</span></tt></dt>
<dd>Tells wget to wait a random time between 0 and double the value specified with &#8211;wait between requests.</dd>
</dl>
</div>
</div>


    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'hackzinewiki'; // required: replace example with your forum shortname
        var disqus_identifier = "scripts/wget-grab-website";
	var disqus_title = "Hackzine Wiki";

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Grabbing a whole site using wget</a><ul>
<li><a class="reference internal" href="#basic-arguments">Basic arguments</a></li>
<li><a class="reference internal" href="#avoiding-imposed-download-limits">Avoiding imposed download limits</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Scripts</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../contributing.html"
                        title="next chapter">Contributing</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/scripts/wget-grab-website.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../contributing.html" title="Contributing"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Scripts"
             >previous</a> |</li>
        <li><a href="../index.html">Hackzine Wiki</a> &raquo;</li>
          <li><a href="index.html" >Scripts</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2012-2014, Samuele ~redShadow~ Santi.
      Last updated on 2014-03-01 00:28:30 +0100.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.1.
    </div>
  </body>
</html>